{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from keras.layers import Input, BatchNormalization, Dense, Add, Activation, Reshape, Permute, Flatten, Conv2DTranspose\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG19\n",
    "import datetime\n",
    "import random\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "ratio = 4\n",
    "LR_shape = (120, 160, 3)\n",
    "\n",
    "L_h, L_w, channels = LR_shape\n",
    "H_h = L_h * ratio\n",
    "H_w = L_w * ratio\n",
    "HR_shape = (H_h, H_w, channels)\n",
    "\n",
    "optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size):\n",
    "\n",
    "    files = glob.glob(\"images/train/*.png\", recursive=True)\n",
    "    batch_images = random.sample(files, batch_size)\n",
    "\n",
    "    hr_imgs = []\n",
    "    lr_imgs = []\n",
    "    for img_path in batch_images:\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        hr_img = img.resize((H_w, H_h))  #(64, 64)\n",
    "        lr_img = img.resize((L_w, L_h))\n",
    "        hr_img = np.array(hr_img)\n",
    "        lr_img = np.array(lr_img)\n",
    "\n",
    "        hr_imgs.append(hr_img)\n",
    "        lr_imgs.append(lr_img)\n",
    "\n",
    "    hr_imgs = np.array(hr_imgs) / 127.5 - 1.\n",
    "    lr_imgs = np.array(lr_imgs) / 127.5 - 1.\n",
    "\n",
    "    return hr_imgs, lr_imgs\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pixel_shuffle(in_map, h, w, c):\n",
    "    \n",
    "    x = Reshape((h, w, 2, 2, c))(in_map)\n",
    "    x = Permute((3, 1, 4, 2, 5))(x)\n",
    "    out_map = Reshape((2 * h, 2 * w, c))(x)\n",
    "    \n",
    "    return out_map\n",
    "\n",
    "\n",
    "def upsampling(in_map, h, w, c):\n",
    "    \n",
    "    x = Conv2D(filters = 4 * c, \n",
    "                     kernel_size = 3,\n",
    "                     strides = 1,\n",
    "                     padding = \"same\")(in_map)\n",
    "    x = pixel_shuffle(x, h, w, c)\n",
    "    out_map = PReLU()(x)\n",
    "    \n",
    "    return out_map\n",
    "\n",
    "\n",
    "def residual_block(in_map):\n",
    "    x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(in_map)\n",
    "    x = LeakyReLU(alpha = 0)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    out_map = Add()([x, in_map])\n",
    "    return out_map\n",
    "\n",
    "\n",
    "def d_block(in_map, filters, kernel_size, strides, padding):\n",
    "    d = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding)(in_map)\n",
    "    d = LeakyReLU(alpha = 0.2)(d)\n",
    "    d = BatchNormalization(momentum = 0.8)(d)\n",
    "    return d\n",
    "\n",
    "\n",
    "def deconv2d(layer_input):\n",
    "    \"\"\"Layers used during upsampling\"\"\"\n",
    "    u = Conv2DTranspose(120, kernel_size = 3,\n",
    "                        strides=2, padding='same')(layer_input)\n",
    "    u = Activation('relu')(u)\n",
    "    return u\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    input_img = Input(shape = LR_shape)\n",
    "    middle = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(input_img)\n",
    "    middle = LeakyReLU(alpha = 0)(middle)\n",
    "    \n",
    "    g = residual_block(middle)\n",
    "    for _ in range(4):\n",
    "        g = residual_block(g)\n",
    "\n",
    "    g = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(g)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = Add()([g, middle])\n",
    "\n",
    "    n = ratio\n",
    "    i = 1\n",
    "    while(n % 2 == 0):\n",
    "        g = deconv2d(g)\n",
    "        n = n // 2\n",
    "\n",
    "    output_img = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(g)\n",
    "\n",
    "    return Model(input_img, output_img)\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    input_img = Input(shape = HR_shape)\n",
    "    \n",
    "    d = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(input_img)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = d_block(d, filters = 64, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 128, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 128, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 256, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 256, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 512, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 512, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "#     d = Flatten()(d)\n",
    "    d = Dense(512)(d)\n",
    "    d = LeakyReLU(alpha = 0.2)(d)\n",
    "    output = Dense(1, activation = \"sigmoid\")(d)\n",
    "\n",
    "    return Model(input_img, output)\n",
    "\n",
    "\n",
    "def build_vgg():\n",
    "    vgg = VGG19(include_top = False)\n",
    "    return Model(vgg.input, vgg.layers[9].output)\n",
    "    \n",
    "\n",
    "def combined(generator, discriminator, vgg):\n",
    "    input_img = Input(shape = LR_shape)\n",
    "    fake_img = generator(input_img)\n",
    "    \n",
    "    validity = discriminator(fake_img)\n",
    "    features = vgg(fake_img)\n",
    "    \n",
    "    return Model(input_img, [validity, features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "epochs_checkpoint = []\n",
    "\n",
    "def train(epochs, batch_size, interval):\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    real = np.ones((batch_size,) + (H_h // 16, H_w // 16, 1))\n",
    "    fake = np.zeros((batch_size,) + (H_h // 16, H_w // 16, 1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        real_imgs, lr_imgs = load_data(batch_size)\n",
    "        fake_imgs = generator.predict(lr_imgs)\n",
    "        \n",
    "        #Dの訓練\n",
    "        d_loss_real = discriminator.train_on_batch(real_imgs, real)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        #Gの訓練\n",
    "        vgg_features = vgg.predict(real_imgs)\n",
    "        g_loss = srgan.train_on_batch(lr_imgs, [real, vgg_features])\n",
    "        \n",
    "        time = datetime.datetime.now() - start_time\n",
    "        print(\"%d time: %s\" % (epoch+1, time))\n",
    "        \n",
    "        if (epoch+1) % interval == 0:\n",
    "            losses.append((d_loss, g_loss))\n",
    "            epochs_checkpoint.append(epoch+1)\n",
    "            generator.save(\"weights/weight.h5\")\n",
    "            print(\"save weights\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:47: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:351: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3176: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\optimizers.py:675: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 480, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 480, 640, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 480, 640, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 240, 320, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 240, 320, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 240, 320, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 240, 320, 128)     73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 240, 320, 128)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 240, 320, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 120, 160, 128)     147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 120, 160, 128)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 120, 160, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 120, 160, 256)     295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 120, 160, 256)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 120, 160, 256)     1024      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 60, 80, 256)       590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 60, 80, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60, 80, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 60, 80, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 60, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 60, 80, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 30, 40, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 40, 512)       2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30, 40, 512)       262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 30, 40, 512)       0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30, 40, 1)         513       \n",
      "=================================================================\n",
      "Total params: 4,955,969\n",
      "Trainable params: 4,952,257\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 120, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 120, 160, 64)      15616     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_1 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_2 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_3 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_4 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_5 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_6 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 240, 320, 120)     69240     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 240, 320, 120)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 480, 640, 120)     129720    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 480, 640, 120)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 480, 640, 3)       29163     \n",
      "=================================================================\n",
      "Total params: 652,763\n",
      "Trainable params: 651,355\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss = \"mse\",\n",
    "                      optimizer = optimizer,\n",
    "                      metrics = [\"accuracy\"])\n",
    "discriminator.summary()\n",
    "\n",
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3043: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:141: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:146: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 120, 160, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 480, 640, 3)   652763                                       \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 30, 40, 1)     4955969                                      \n",
      "____________________________________________________________________________________________________\n",
      "model_3 (Model)                  multiple              1735488                                      \n",
      "====================================================================================================\n",
      "Total params: 7,344,220\n",
      "Trainable params: 7,339,100\n",
      "Non-trainable params: 5,120\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = build_vgg()\n",
    "vgg.trainable = False\n",
    "discriminator.trainable = False\n",
    "srgan = combined(generator, discriminator, vgg)\n",
    "srgan.compile(loss=['binary_crossentropy', 'mse'],\n",
    "                              loss_weights=[1e-3, 1],\n",
    "                              optimizer=optimizer)\n",
    "srgan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epochs = 3000, batch_size = 1, interval = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
